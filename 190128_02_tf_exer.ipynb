{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "190128_02_tf_exer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "EKZJq9txlc--",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 드롭아웃(dropout)\n",
        "* mnist를 이용해서 신경망을 구성\n",
        "* 신경망에 과적합이 있다.\n",
        "* 학습시 전체 신경망 중에 일부만응 사용한다.\n",
        "* 일부 뉴런을 사용하지 않으므로, 일부 특징이 특정 뉴런에 고정되는 것을 막아 가중치 균형을 잡아준다.\n",
        "* 일부 뉴런을 학습 시키지 않기 때문에 시간이 걸린다."
      ]
    },
    {
      "metadata": {
        "id": "EKB2IjycmLqS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lmhYz0RimTzs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "99549369-310c-489f-cfad-ccc390333817"
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets('./mnist/data/', one_hot = True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-48e8f405681e>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "emgiUh76mii1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 신경망 모델 구성"
      ]
    },
    {
      "metadata": {
        "id": "EO8cfTZwmoHc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 28*28 => 784개의 특징\n",
        "# Label 0~9 까지의 10개 분류\n",
        "# 입력 X, 출력 Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UJMi6otKmwYo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "Y = tf.placeholder(tf.float32, [None, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HOrjqfQMm6FE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 구성하고자 하는 신경망\n",
        "* 784개의 특징(28*28)\n",
        "* 256개의 은닉층의 뉴런 개수\n",
        "* 256개의 은닉층의 뉴런 개수\n",
        "* 10개의 결과 뉴런"
      ]
    },
    {
      "metadata": {
        "id": "kvhDuPPvnXee",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 신경망 구성시에\n",
        "* (1) 임의의 w값을 설정한다.\n",
        "* (2) 신경망 층을 쌓는다.\n",
        "* (3) cost 함수를 지정, optimizer 함수 지정\n",
        "* (4) 신경망의 모델을 학습\n",
        "* (5) 좋은 모델을 가지고 예측 수행"
      ]
    },
    {
      "metadata": {
        "id": "73BH42ghnt0N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "W1 = tf.Variable(tf.random_normal([784, 256], stddev = 0.01))\n",
        "\n",
        "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
        "L1 = tf.nn.dropout(L1, keep_prob)\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([256, 256], stddev = 0.01))\n",
        "\n",
        "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
        "L2 = tf.nn.dropout(L2, keep_prob)\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([256, 10], stddev = 0.01))\n",
        "model = tf.matmul(L2, W3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8AH-xWc0ofeW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### cost, optimizer\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = model, labels = Y))\n",
        "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UKQmtGTmo3hu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### 모델 학습\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t4IqWg4ApAGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "outputId": "99880256-8097-41fc-99c1-7a06d753bc24"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "total_batch = int(mnist.train.num_examples/batch_size) # 500\n",
        "\n",
        "for epoch in range(30):\n",
        "  total_cost = 0\n",
        "  for i in range(total_batch):\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "    \n",
        "    _, cost_val = sess.run([optimizer, cost], feed_dict={X:batch_xs, Y:batch_ys, keep_prob:0.8})\n",
        "    total_cost += cost_val\n",
        "  print('Epoch {} Avg cost = {}'.format(epoch+1, total_cost/total_batch))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Avg cost = 0.43305880596014584\n",
            "Epoch 2 Avg cost = 0.16584588108414952\n",
            "Epoch 3 Avg cost = 0.11530092805285345\n",
            "Epoch 4 Avg cost = 0.09166127300059254\n",
            "Epoch 5 Avg cost = 0.07341238337653605\n",
            "Epoch 6 Avg cost = 0.061222568316046486\n",
            "Epoch 7 Avg cost = 0.05319348062134602\n",
            "Epoch 8 Avg cost = 0.047824090075975455\n",
            "Epoch 9 Avg cost = 0.042028678569265385\n",
            "Epoch 10 Avg cost = 0.03831807693085548\n",
            "Epoch 11 Avg cost = 0.03189928762762892\n",
            "Epoch 12 Avg cost = 0.032718339633429426\n",
            "Epoch 13 Avg cost = 0.02896508825900541\n",
            "Epoch 14 Avg cost = 0.02783498698517426\n",
            "Epoch 15 Avg cost = 0.02706777623992159\n",
            "Epoch 16 Avg cost = 0.025668048902007287\n",
            "Epoch 17 Avg cost = 0.021295449913992674\n",
            "Epoch 18 Avg cost = 0.02227773681314747\n",
            "Epoch 19 Avg cost = 0.021293383978402497\n",
            "Epoch 20 Avg cost = 0.020820055703701323\n",
            "Epoch 21 Avg cost = 0.019444515997919635\n",
            "Epoch 22 Avg cost = 0.02046521708906353\n",
            "Epoch 23 Avg cost = 0.017394219884114468\n",
            "Epoch 24 Avg cost = 0.01647827794047771\n",
            "Epoch 25 Avg cost = 0.019851892738416525\n",
            "Epoch 26 Avg cost = 0.019100481153912947\n",
            "Epoch 27 Avg cost = 0.017187711071138354\n",
            "Epoch 28 Avg cost = 0.014911752491818996\n",
            "Epoch 29 Avg cost = 0.015333412063409924\n",
            "Epoch 30 Avg cost = 0.016801028416018448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o70wxuq8pxfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9bccbf6e-277c-46d6-e200-b448bfda7b9c"
      },
      "cell_type": "code",
      "source": [
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1)) # 예측값, 실제값\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "accuracy"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Mean_1:0' shape=() dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "TtgLYn1IqkXQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "95039182-1194-472a-9087-757e0ffcee48"
      },
      "cell_type": "code",
      "source": [
        "print('정확도', sess.run(accuracy, feed_dict={X:mnist.test.images,\n",
        "                                          Y:mnist.test.labels,\n",
        "                                          keep_prob:1}))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정확도 0.9829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ar3kr6lgqziC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 실습"
      ]
    },
    {
      "metadata": {
        "id": "9jK7eVPOra7W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "W1 = tf.Variable(tf.random_normal([784, 128], stddev=0.01))\n",
        "\n",
        "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
        "L1 = tf.nn.dropout(L1, keep_prob)\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([128, 128], stddev=0.01))\n",
        "\n",
        "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
        "L2 = tf.nn.dropout(L2, keep_prob)\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([128, 10], stddev=0.01))\n",
        "model = tf.matmul(L2, W3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TlD64l5msra1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### cost, optimizer\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RVuM6_CQs-c6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### 모델 학습\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vMuwTAvotHeo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BY3MzbAEtLQr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "0b9bd740-7f35-4eac-8181-0b5f4f349ba4"
      },
      "cell_type": "code",
      "source": [
        "batch_size =100\n",
        "total_batch = int(mnist.train.num_examples/batch_size) # 500\n",
        "\n",
        "for epoch in range(30):\n",
        "  total_cost = 0\n",
        "  for i in range(total_batch):\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "    \n",
        "    _, cost_val = sess.run([optimizer, cost], feed_dict={X:batch_xs, Y:batch_ys, keep_prob:0.5})\n",
        "    total_cost += cost_val\n",
        "  print('Epoch {} Avg cost = {}'.format(epoch+1, total_cost/total_batch))\n",
        "  \n",
        "print('--- %s seconds ---' %(time.time() - start_time))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Avg cost = 0.7054379110173745\n",
            "Epoch 2 Avg cost = 0.3407763865048235\n",
            "Epoch 3 Avg cost = 0.27548802337863226\n",
            "Epoch 4 Avg cost = 0.2427270949564197\n",
            "Epoch 5 Avg cost = 0.22205849602141164\n",
            "Epoch 6 Avg cost = 0.20661419117992574\n",
            "Epoch 7 Avg cost = 0.19275341174141927\n",
            "Epoch 8 Avg cost = 0.1831839122250676\n",
            "Epoch 9 Avg cost = 0.17614049482751976\n",
            "Epoch 10 Avg cost = 0.17091489126059142\n",
            "Epoch 11 Avg cost = 0.16419079366732728\n",
            "Epoch 12 Avg cost = 0.1603831361979246\n",
            "Epoch 13 Avg cost = 0.1557085796919736\n",
            "Epoch 14 Avg cost = 0.1469537132301114\n",
            "Epoch 15 Avg cost = 0.1503774639489976\n",
            "Epoch 16 Avg cost = 0.14600667924366215\n",
            "Epoch 17 Avg cost = 0.14180555211210794\n",
            "Epoch 18 Avg cost = 0.1386242729391564\n",
            "Epoch 19 Avg cost = 0.13972005956552244\n",
            "Epoch 20 Avg cost = 0.13305315388197247\n",
            "Epoch 21 Avg cost = 0.1320198329910636\n",
            "Epoch 22 Avg cost = 0.1316459025916728\n",
            "Epoch 23 Avg cost = 0.126786503019658\n",
            "Epoch 24 Avg cost = 0.12694192786108363\n",
            "Epoch 25 Avg cost = 0.12690055581317705\n",
            "Epoch 26 Avg cost = 0.12478275623849847\n",
            "Epoch 27 Avg cost = 0.13046414889395236\n",
            "Epoch 28 Avg cost = 0.12082449051128193\n",
            "Epoch 29 Avg cost = 0.12096018621867353\n",
            "Epoch 30 Avg cost = 0.1169795805757696\n",
            "--- 327.0427589416504 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t1MGzQCZuFpF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "94df8901-d750-46b2-d217-747f28f32a32"
      },
      "cell_type": "code",
      "source": [
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1)) # 예측값, 실제값\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "accuracy"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Mean_3:0' shape=() dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "sHad-yvBu6ri",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "54a5346c-bc81-4d4b-b0d6-bd3d519ee52c"
      },
      "cell_type": "code",
      "source": [
        "print('정확도', sess.run(accuracy, feed_dict={X:mnist.test.images,\n",
        "                                          Y:mnist.test.labels,\n",
        "                                          keep_prob:1}))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정확도 0.975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZmI4CPyyvHsE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# GAN\n",
        "* 비지도 학습 방법"
      ]
    },
    {
      "metadata": {
        "id": "-NDUAzMhvUmv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "ac6f1ddf-8330-4901-ae03-1e340eca4f7e"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('./mnist/data/', one_hot=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_Ck3PKkAvky5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 01. 기본 옵션 설정"
      ]
    },
    {
      "metadata": {
        "id": "Z0w5U8NWvqUe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "total_epoch = 100 # epoch 수 설정 (왕복 횟수)\n",
        "batch_size = 100 # 배치 사이즈\n",
        "learning_rate = 0.0002 # 학습률 ( 매우 느리게)\n",
        "\n",
        "# 신경망 레이어 구성 옵션\n",
        "## 은닉층의 노드 수 결정\n",
        "n_hidden = 256\n",
        "## 입력층의 갯수\n",
        "n_input = 28*28\n",
        "## 페이크 생성기의 입력값으로 사용할 노이즈(데이터)의 크기(갯수)\n",
        "n_noise = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a9XfVMHZwG9-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 02. 신경망 모델 구성\n",
        "* 노이즈를 이용한 데이터 생성\n",
        "* 비지도 학습으로 Y가 없음"
      ]
    },
    {
      "metadata": {
        "id": "dBqXxWw1wQWc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## 판별기에 들어갈 입력\n",
        "X = tf.placeholder(tf.float32, [None, n_input])\n",
        "\n",
        "## 페이크 생성기에 들어갈 입력\n",
        "Z = tf.placeholder(tf.float32, [None, n_noise])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TIuTQxNowip-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 생성기의 가중치(W)와 바이어스(b)"
      ]
    },
    {
      "metadata": {
        "id": "fGwnK_AQwo-q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 128*256 개의 W1\n",
        "# 128 개의 b1\n",
        "\n",
        "G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev = 0.01))\n",
        "G_b1 = tf.Variable(tf.zeros([n_hidden])) # 256\n",
        "\n",
        "G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev=0.01))\n",
        "G_b2 = tf.Variable(tf.zeros([n_input])) # 784\n",
        "\n",
        "#G_W1 = tf.Variable(tf.random_normal([128, 256], stddev=0.01))\n",
        "#G_b1 = tf.Variable(tf.zeros([256])) # 256\n",
        "\n",
        "#G_W2 = tf.Variable(tf.random_normal([256, 784], stddev=0.01))\n",
        "#G_b2 = tf.Variable(tf.zeros([784])) # 784"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "COQxyg2Yx9i8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 구분자의 신경망 변수 선언(W, b)\n",
        "* 은닉층이 들어가면 선형 뿐만 아니라 비선형 문제도 풀 수 있다.\n",
        "* 은닉층이 없으면 선형문제만 풀 수 있다."
      ]
    },
    {
      "metadata": {
        "id": "5zpWzoSWyXI3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "D_W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
        "D_b1 = tf.Variable(tf.zeros([n_hidden])) # 258\n",
        "\n",
        "D_W2 = tf.Variable(tf.random_normal([256, 1], stddev = 0.01))\n",
        "D_b2 = tf.Variable(tf.zeros([1])) # 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mw3g8i7pyxqe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 생성기의 신경망 구성"
      ]
    },
    {
      "metadata": {
        "id": "qkppu4Y2y2n4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator(noise_z):\n",
        "  hidden = tf.nn.relu(tf.matmul(noise_z, G_W1) + G_b1) # 은닉층 거친 결과\n",
        "  output = tf.nn.sigmoid(tf.matmul(hidden, G_W2) + G_b2) # 2번째 거친 결과(128)\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eIsUPVFXzRiM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 구분자의 신경망 구성"
      ]
    },
    {
      "metadata": {
        "id": "S6P1T-cO9j0B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def discriminator(inputs):\n",
        "  hidden = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
        "  output = tf.nn.sigmoid(tf.matmul(hidden, D_W2) + D_b2)\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lNihg82396du",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#def discriminator(inputs):\n",
        "#  hidden = tf.nn.relu(tf.matmul(inputs, D_W1) +D_b1) # 은닉층 거친 결과\n",
        "#  output = tf.nn.sigmoid(tf.matmul(hidden, D_W2) + D_b2)\n",
        "#  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JB8mYai5-hLT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 위의 noise_z를 발생시킬 노이즈 생성 함수"
      ]
    },
    {
      "metadata": {
        "id": "zrTJ2rnj-liZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_noise(batch_size, n_noise):\n",
        "  return np.random.normal(size = (batch_size, n_noise))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IJuuPmEu-tm5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 노이즈를 이용해서 랜덤한 이미지를 생성\n",
        "G = generator(Z)\n",
        "\n",
        "# 노이즈를 이용해서 생성한 이미지(정보)를 구분자에 넣어서 결과(판별값0~1)을 본다.\n",
        "D_fake = discriminator(G)\n",
        "\n",
        "# 진짜 이미지를 이용해서 판별한 값을 구한다.\n",
        "D_real = discriminator(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W-Cbnm2H_CuY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.\n",
        "* loss\n",
        "* optimizer\n",
        "* 진짜 이미지를 넣었을 때, 최대값(tf.log(D_real))\n",
        "* 가짜 이미지를 넣었을 때, 최대값 tf.log(1-D_fake)"
      ]
    },
    {
      "metadata": {
        "id": "7OvFJgba_ZRn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1-D_fake))\n",
        "## 생성자의 loss\n",
        "loss_G = tf.reduce_mean(tf.log(D_fake))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ej1TS1AT_nbp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "D_var_list = [D_W1, D_b1, D_W2, D_b2] # 구분자의 변수들\n",
        "G_var_list = [G_W1, G_b1, G_W2, G_b2] # 생성자의 변수들"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FnoSNogI_3tJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GAN 논문의 수식에 따르면 loss를 극대화 해야하지만, minimize 하는 최적화 함수를 사용하기 때문에\n",
        "# 최적화 하려는 loss_D와 loss_G에 음수 부호를 붙여준다.\n",
        "train_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D, var_list = D_var_list)\n",
        "train_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G, var_list = G_var_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QN1uOTIBAS2e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "total_batch = int(mnist.train.num_examples/batch_size)\n",
        "loss_val_D, loss_val_G = 0, 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pfVBCk6EAgy7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zHQmsAagAilx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "outputId": "3e535fe7-f7de-4575-fc6a-c5d35ffa951b"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for epoch in range(total_epoch):\n",
        "  for i in range(total_batch):\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "    noise = get_noise(batch_size, n_noise)\n",
        "    # 판별기와 생성기 신경망을 각각 학습시킨다.\n",
        "    _, loss_var_D = sess.run([train_D, loss_D],\n",
        "    feed_dict = {X: batch_xs, Z:noise})\n",
        "    _, loss_val_G = sess.run([train_G, loss_G],\n",
        "                            feed_dict={Z:noise})\n",
        "  print('Epoch:', '%04d' % epoch,\n",
        "       'D loss: {:.4}'.format(loss_val_D),\n",
        "       'G loss: {:.4}'.format(loss_val_G))\n",
        "  \n",
        "  # 학습이 되어가는 모습을 보기 위해 주기적으로 이미지를 생성하여 저장\n",
        "  if epoch == 0 or (epoch + 1) % 10 ==0:\n",
        "    sample_size = 10\n",
        "    nise = get_noise(sample_size, n_noise)\n",
        "    samples = sess.run(G, feed_dict={Z:noise})\n",
        "    fig, ax = plt.subplots(1, sample_size, figsize = (sample_size, 1))\n",
        "    \n",
        "    for i in range(sample_size):\n",
        "      ax[i].set_axis_off()\n",
        "      ax[i].imshow(np.reshape(samples[i], (28,28)))\n",
        "    plt.savefig('samples/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "print('최적화 완료')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-19b98f39e3d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"for epoch in range(total_epoch):\\n  for i in range(total_batch):\\n    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\\n    noise = get_noise(batch_size, n_noise)\\n    # 판별기와 생성기 신경망을 각각 학습시킨다.\\n    _, loss_var_D = sess.run([train_D, loss_D],\\n    feed_dict = {X: batch_xs, Z:noise})\\n    _, loss_val_G = sess.run([train_G, loss_G],\\n                            feed_dict={Z:noise})\\n  print('Epoch:', '%04d' % epoch,\\n       'D loss: {:.4}'.format(loss_val_D),\\n       'G loss: {:.4}'.format(loss_val_G))\\n  \\n  # 학습이 되어가는 모습을 보기 위해 주기적으로 이미지를 생성하여 저장\\n  if epoch == 0 or (epoch + 1) % 10 ==0:\\n    sample_size = 10\\n    nise = get_noise(sample_size, n_noise)\\n    samples = sess.run(G, feed_dict={Z:noise})\\n    fig, ax = plt.subplots(1, sample_size, figsize = (sample_size, 1))\\n    \\n    for i in range(sample_size):\\n      ax[i].set_axis_off()\\n      ax[i].imshow(np.reshape(samples[i], (28,28)))\\n    plt.savefig('samples/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\\n    plt.close(fig)\\nprint('최적화 완료')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Precision not allowed in integer format specifier"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "64kzUZsqCZj9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}