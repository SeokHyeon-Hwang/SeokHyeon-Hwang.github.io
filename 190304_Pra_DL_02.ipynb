{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습과제 2-1\n",
    "\n",
    " MNIST 데이터 셋 or 기타 데이터 셋을 이용한 아래 조건을 만족하는 DNN 신경망을 구현해 주세요.<br>\n",
    "(1) 은닉층을 2개 이상으로 구성.<br>\n",
    "(2) 배치 사이즈를 200으로 구성.<br>\n",
    "(3) 최적화 알고리즘은 Gradient Decent알고리즘을 이용.<br>\n",
    "(5) 학습 중의 cost 값을 출력.<br>\n",
    "(4) Learning rate 기본값 0.1로 지정.<br>\n",
    "(5) 학습 중의 cost 값을 출력.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-6fa84048fdd1>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 은닉층 3개\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1)) \n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256,256], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2)) \n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "model = tf.matmul(L2, W3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "total_batch = int(mnist.train.num_examples / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 784) (200, 10)\n",
      "Epoch 1, Avg. cost = 0.3605393932353366\n",
      "(200, 784) (200, 10)\n",
      "Epoch 2, Avg. cost = 0.11677762553095818\n",
      "(200, 784) (200, 10)\n",
      "Epoch 3, Avg. cost = 0.07836230725049972\n",
      "(200, 784) (200, 10)\n",
      "Epoch 4, Avg. cost = 0.05885798857970671\n",
      "(200, 784) (200, 10)\n",
      "Epoch 5, Avg. cost = 0.04586162625388666\n",
      "(200, 784) (200, 10)\n",
      "Epoch 6, Avg. cost = 0.03499223522672599\n",
      "(200, 784) (200, 10)\n",
      "Epoch 7, Avg. cost = 0.026452245514162562\n",
      "(200, 784) (200, 10)\n",
      "Epoch 8, Avg. cost = 0.021037851172414693\n",
      "(200, 784) (200, 10)\n",
      "Epoch 9, Avg. cost = 0.01635954795066606\n",
      "(200, 784) (200, 10)\n",
      "Epoch 10, Avg. cost = 0.012816948741251095\n",
      "(200, 784) (200, 10)\n",
      "Epoch 11, Avg. cost = 0.010098240779374134\n",
      "(200, 784) (200, 10)\n",
      "Epoch 12, Avg. cost = 0.007996158317493444\n",
      "(200, 784) (200, 10)\n",
      "Epoch 13, Avg. cost = 0.006077025228349323\n",
      "(200, 784) (200, 10)\n",
      "Epoch 14, Avg. cost = 0.004753055518958718\n",
      "(200, 784) (200, 10)\n",
      "Epoch 15, Avg. cost = 0.003908379459541969\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "  total_cost = 0\n",
    "  for i in range(total_batch):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "    _, cost_val = sess.run([optimizer,cost], feed_dict={X:batch_xs, Y:batch_ys})\n",
    "    total_cost += cost_val\n",
    "  print(batch_xs.shape, batch_ys.shape)\n",
    "  print('Epoch {}, Avg. cost = {}'.format(epoch+1, total_cost/total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_2:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "is_correct\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.test.images.shape)\n",
    "print(mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 0.9823\n"
     ]
    }
   ],
   "source": [
    "print('정확도', sess.run(accuracy, feed_dict={X:mnist.test.images,\n",
    "Y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 과제 2-2 [기본항목 5-3] – 10점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실습과제 2-1에서 구현한 심층 신경망에 대해 하이퍼 파라미터를 변경하여 성능 개선을 수행해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 은닉층 4개로 늘림\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1)) \n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256,256], stddev=0.01))\n",
    "\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2)) \n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3))\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([256, 10]))\n",
    "model = tf.matmul(L3, W4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "# learning_rate = 0.01로 바꿈\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치사이즈 그대로\n",
    "batch_size = 200\n",
    "total_batch = int(mnist.train.num_examples / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 784) (200, 10)\n",
      "Epoch 1, Avg. cost = 1.75525694955479\n",
      "(200, 784) (200, 10)\n",
      "Epoch 2, Avg. cost = 0.5026556508107619\n",
      "(200, 784) (200, 10)\n",
      "Epoch 3, Avg. cost = 0.36848704413934186\n",
      "(200, 784) (200, 10)\n",
      "Epoch 4, Avg. cost = 0.3207231077822772\n",
      "(200, 784) (200, 10)\n",
      "Epoch 5, Avg. cost = 0.2882307554916902\n",
      "(200, 784) (200, 10)\n",
      "Epoch 6, Avg. cost = 0.26023744664408943\n",
      "(200, 784) (200, 10)\n",
      "Epoch 7, Avg. cost = 0.2365041268413717\n",
      "(200, 784) (200, 10)\n",
      "Epoch 8, Avg. cost = 0.21538032759319653\n",
      "(200, 784) (200, 10)\n",
      "Epoch 9, Avg. cost = 0.19735691804777492\n",
      "(200, 784) (200, 10)\n",
      "Epoch 10, Avg. cost = 0.18187845899300142\n",
      "(200, 784) (200, 10)\n",
      "Epoch 11, Avg. cost = 0.16817974442785436\n",
      "(200, 784) (200, 10)\n",
      "Epoch 12, Avg. cost = 0.155978123979135\n",
      "(200, 784) (200, 10)\n",
      "Epoch 13, Avg. cost = 0.1459264136715369\n",
      "(200, 784) (200, 10)\n",
      "Epoch 14, Avg. cost = 0.1367238930409605\n",
      "(200, 784) (200, 10)\n",
      "Epoch 15, Avg. cost = 0.1274146137318828\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "  total_cost = 0\n",
    "  for i in range(total_batch):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "    _, cost_val = sess.run([optimizer,cost], feed_dict={X:batch_xs, Y:batch_ys})\n",
    "    total_cost += cost_val\n",
    "  print(batch_xs.shape, batch_ys.shape)\n",
    "  print('Epoch {}, Avg. cost = {}'.format(epoch+1, total_cost/total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_4:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "is_correct\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.test.images.shape)\n",
    "print(mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 0.9611\n"
     ]
    }
   ],
   "source": [
    "print('정확도', sess.run(accuracy, feed_dict={X:mnist.test.images,\n",
    "Y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미 정확도가 높았던 모델이 었던지라 learning_rate를 올리고, 은닉층 수를 늘렸더니 정확도가 낮아졌다. 과적합에 따른 것으로 추측된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 과제 2-3 [기본항목 5-4] – 10점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서플로(Tensorflow)를 활용한 CNN 알고리즘을 구현해 주세요.(5점)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mnist 데이터 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data\\train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data\\t10k-labels-idx1-ubyte.gz\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('./mnist/data', one_hot=True)\n",
    "print(mnist.train.labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구성\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1)) \n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "                \n",
    "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L2, W3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost 함수 & 최적화\n",
    "cost = tf.reduce_mean(tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y)))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =100\n",
    "total_batch=int(mnist.train.num_examples/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 784) (100, 10)\n",
      "Epoch 1, Avg. cost = 0.40301885373213076\n",
      "(100, 784) (100, 10)\n",
      "Epoch 2, Avg. cost = 0.14947040980173784\n",
      "(100, 784) (100, 10)\n",
      "Epoch 3, Avg. cost = 0.09869709553197026\n",
      "(100, 784) (100, 10)\n",
      "Epoch 4, Avg. cost = 0.07076648479835554\n",
      "(100, 784) (100, 10)\n",
      "Epoch 5, Avg. cost = 0.05256265942769294\n",
      "(100, 784) (100, 10)\n",
      "Epoch 6, Avg. cost = 0.03818838015114042\n",
      "(100, 784) (100, 10)\n",
      "Epoch 7, Avg. cost = 0.02885897215286439\n",
      "(100, 784) (100, 10)\n",
      "Epoch 8, Avg. cost = 0.026006143620153042\n",
      "(100, 784) (100, 10)\n",
      "Epoch 9, Avg. cost = 0.022817325338626026\n",
      "(100, 784) (100, 10)\n",
      "Epoch 10, Avg. cost = 0.016735193543903404\n",
      "(100, 784) (100, 10)\n",
      "Epoch 11, Avg. cost = 0.017173856748056344\n",
      "(100, 784) (100, 10)\n",
      "Epoch 12, Avg. cost = 0.014015165606741159\n",
      "(100, 784) (100, 10)\n",
      "Epoch 13, Avg. cost = 0.010984961638989096\n",
      "(100, 784) (100, 10)\n",
      "Epoch 14, Avg. cost = 0.013273910916349533\n",
      "(100, 784) (100, 10)\n",
      "Epoch 15, Avg. cost = 0.01047957661017294\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "  total_cost = 0\n",
    "  for i in range(total_batch):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size) # 학습할 데이터를 가져온다.\n",
    "    \n",
    "    # 입력 X, 출력 Y에 각각의 데이터 넣고 실행\n",
    "    _, cost_val = sess.run([optimizer,cost],\n",
    "                          feed_dict={X:batch_xs, Y:batch_ys})\n",
    "    total_cost += cost_val\n",
    "  print(batch_xs.shape, batch_ys.shape)\n",
    "  print('Epoch {}, Avg. cost = {}'.format(epoch+1, total_cost/total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000, 10)\n",
      "Tensor(\"MatMul_9:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"Equal_3:0\", shape=(?,), dtype=bool)\n",
      "Tensor(\"Mean_7:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.test.images.shape)\n",
    "print(mnist.test.labels.shape)\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1)) \n",
    "is_correct\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "accuracy\n",
    "print(model)\n",
    "print(is_correct)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000, 10)\n",
      "정확도 0.9771\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(mnist.test.images.shape)\n",
    "print(mnist.test.labels.shape)\n",
    "print('정확도', sess.run(accuracy, feed_dict={X:mnist.test.images,\n",
    "                                              Y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로(Tensorflow)를 활용한 RNN 알고리즘을 구현해 주세요.(5점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어의 마지막 알파벳 맞추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_arr = ['a', 'b', 'c', 'd', 'e', 'f', 'g',\n",
    "            'h', 'i', 'j', 'k', 'l', 'm', 'n',\n",
    "            'o', 'p', 'q', 'r', 's', 't', 'u',\n",
    "            'v', 'w', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "dic_len = len(num_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = ['clock', 'charm', 'water', 'knock', 'cloud', 'sunny', 'apple', 'funny', 'lower', 'knife']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(seq_data):\n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "\n",
    "    for seq in seq_data:\n",
    "\n",
    "        input = [num_dic[n] for n in seq[:-1]]\n",
    "\n",
    "        target = num_dic[seq[-1]]\n",
    "\n",
    "        input_batch.append(np.eye(dic_len)[input])\n",
    "\n",
    "        target_batch.append(target)\n",
    "\n",
    "    return input_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "n_hidden = 100\n",
    "total_epoch = 15\n",
    "\n",
    "n_step = 4\n",
    "\n",
    "n_input = n_class = dic_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_step, n_input])\n",
    "\n",
    "Y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_hidden, n_class]))\n",
    "b = tf.Variable(tf.random_normal([n_class]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-43-fea100b0b962>:2: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n"
     ]
    }
   ],
   "source": [
    "# RNN 셀 생성\n",
    "cell1 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "# Drop out 기법으로 과적합 방지\n",
    "cell1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=0.5)\n",
    "# 셀 추가 생성\n",
    "cell2 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "\n",
    "cell3 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "\n",
    "# 조합한 RNN 셀 생성\n",
    "multi_cell = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2, cell3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순환 신경망 만들기\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 결과 : one-hot 인코딩 형식\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "outputs = outputs[-1]\n",
    "model = tf.matmul(outputs, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits=model, labels=Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 3.485882\n",
      "Epoch: 0002 cost = 3.006522\n",
      "Epoch: 0003 cost = 2.042243\n",
      "Epoch: 0004 cost = 1.265347\n",
      "Epoch: 0005 cost = 1.481086\n",
      "Epoch: 0006 cost = 0.707447\n",
      "Epoch: 0007 cost = 0.475606\n",
      "Epoch: 0008 cost = 0.389120\n",
      "Epoch: 0009 cost = 0.340970\n",
      "Epoch: 0010 cost = 0.285468\n",
      "Epoch: 0011 cost = 0.261061\n",
      "Epoch: 0012 cost = 0.226736\n",
      "Epoch: 0013 cost = 0.163568\n",
      "Epoch: 0014 cost = 0.174560\n",
      "Epoch: 0015 cost = 0.153760\n",
      "완료!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "input_batch, target_batch = make_batch(seq_data)\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    _, loss = sess.run([optimizer, cost],\n",
    "                       feed_dict={X: input_batch, Y: target_batch})\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "print('완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 예측 결과 ===\n",
      "입력값: ['cloc ', 'char ', 'wate ', 'knoc ', 'clou ', 'sunn ', 'appl ', 'funn ', 'lowe ', 'knif ']\n",
      "예측값: ['clock', 'charm', 'water', 'knock', 'cloud', 'sunny', 'apple', 'funny', 'lower', 'knife']\n",
      "정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 예측값을 정수로 변경\n",
    "prediction = tf.cast(tf.argmax(model, 1), tf.int32)\n",
    "\n",
    "prediction_check = tf.equal(prediction, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction_check, tf.float32))\n",
    "\n",
    "input_batch, target_batch = make_batch(seq_data)\n",
    "\n",
    "predict, accuracy_val = sess.run([prediction, accuracy],\n",
    "                                 feed_dict={X: input_batch, Y: target_batch})\n",
    "\n",
    "predict_words = []\n",
    "for idx, val in enumerate(seq_data):\n",
    "    last_char = char_arr[predict[idx]]\n",
    "    predict_words.append(val[:4] + last_char)\n",
    "\n",
    "print('\\n=== 예측 결과 ===')\n",
    "print('입력값:', [w[:4] + ' ' for w in seq_data])\n",
    "print('예측값:', predict_words)\n",
    "print('정확도:', accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
