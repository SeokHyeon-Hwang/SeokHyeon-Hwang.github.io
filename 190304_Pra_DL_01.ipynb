{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 능력단위 평가 - 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 과제 1-1 [기본항목 1-3, 1-4] – 10점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1차원 배열 간의 [10, 10], [3, 5] 의 행렬의 내적(dot)를 구해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "d = np.array([10, 10])\n",
    "e = np.array([3, 5])\n",
    "print(np.dot(d, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아래 행렬에 대한 연산을 numpy를 이용하여 계산해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (가) 2를 곱하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 3]\n",
      " [2 1]]\n",
      "[[10  6]\n",
      " [ 4  2]]\n"
     ]
    }
   ],
   "source": [
    "d = np.array([[5,3], [2,1]])\n",
    "print(d)\n",
    "print(2*d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (나) 행렬의 덧셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  6]\n",
      " [ 4  2]]\n"
     ]
    }
   ],
   "source": [
    "d = np.array([[5,3], [2,1]])\n",
    "e = np.array([[5,3], [2,1]])\n",
    "print(d+e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([5.3]), list([2, 1])], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2 Tensorflow는 그래프의 생성과 그래프의 실행으로 나눌 수 있다. 아래 내용에 따라 파이썬 프로그램을 작성해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 두 개의 값을 선언하고 이에 대한 곱에 대한 결과를 확인해 보자.<br>\n",
    "(가) a=15, b=30의 값을 저장한다.<br>\n",
    "(나) c는 두 값의 곱의 값을 저장한다.<br>\n",
    "(다) 값을 확인하기 위한 세션을 선언하고 이를 실행하여 a, b, c의 값을 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(15)\n",
    "b = tf.constant(30)\n",
    "c = tf.multiply(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  15\n",
      "b =  30\n",
      "c =  450\n"
     ]
    }
   ],
   "source": [
    "sess  = tf.Session()\n",
    "print('a = ', sess.run(a))\n",
    "print('b = ', sess.run(b))\n",
    "print('c = ', sess.run(c))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 아래 행렬 연산을 수행하는 프로그램을 작성해 보자.<br>\n",
    "\n",
    "(가) R(임의 값) x 4의 행렬을 X를 선언한다. 내용은 실수 값을 갖는다. (Tensor형, 플레이스 홀더)<br>\n",
    "(나) W, b의 값을 random_norma를 이용하여 값을 지정 W : 4 x 3 , b : 3 x 1<br>\n",
    "(다) Y = X * W + b를 만족시키는 식을 구하고, 이에 대한 결과를 확인해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[3,4,5,6], [7,8,9,10], [1,2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([4, 3]))\n",
    "b = tf.Variable(tf.random_normal([3, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--x_data--\n",
      "[[3, 4, 5, 6], [7, 8, 9, 10], [1, 2, 3, 4]]\n",
      "--W matrix--\n",
      "[[ 0.4048495   0.9868611   0.39601076]\n",
      " [ 0.04500555  0.12342189 -0.8719522 ]\n",
      " [-0.08563911 -0.668734    0.29411003]\n",
      " [ 0.17409867  0.38429895 -1.4154762 ]]\n",
      "--Y_pred--\n",
      "[[  2.5959365   3.001364   -8.737114 ]\n",
      " [  5.037427    6.5929875 -14.838113 ]\n",
      " [  1.7701788   1.6005396  -5.2916274]]\n"
     ]
    }
   ],
   "source": [
    "# 그래프 실행\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('--x_data--')\n",
    "print(x_data)\n",
    "print('--W matrix--')\n",
    "print(sess.run(W))\n",
    "print('--Y_pred--')\n",
    "print(sess.run(Y_pred, feed_dict={X:x_data}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow를 활용하여 단순/다중 선형회귀 모형을 구현해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(가) Learning rate(학습률)로 0.01로 지정한다.<br>\n",
    "(나) 손실함수 (Loss) 함수를 10개 - cost 비용<br>\n",
    "(다) 최적화 함수로 GradientDescent 알고리즘을 사용한다.<br>\n",
    "(라) 학습이 수행될 때, 최소 10번에 한번꼴로 해당 loss와 W값이 출력 되도록 한다.<br>\n",
    "\n",
    "(다중 선형 회귀 모형의 경우 약간의 가산점이 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1,2,3,4,5]\n",
    "y_data = [10, 20, 30, 40, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_4:0' shape=(1,) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_5:0' shape=(1,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "print(W)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_2:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "T = tf.placeholder(tf.float32)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X:0\", dtype=float32)\n",
      "Tensor(\"Y:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, name='X')\n",
    "Y = tf.placeholder(tf.float32, name='Y')\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = W*X +b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"GradientDescent\"\n",
      "op: \"NoOp\"\n",
      "input: \"^GradientDescent/update_Variable_4/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_5/ApplyGradientDescent\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)\n",
    "print(train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 897.67615 [2.7372265] [1.3346624]\n",
      "1 523.84784 [4.2549567] [1.7437356]\n",
      "2 305.99432 [5.414242] [2.0535634]\n",
      "3 179.0352 [6.299895] [2.2876375]\n",
      "4 105.04486 [6.97666] [2.463891]\n",
      "5 61.92212 [7.4939613] [2.5960135]\n",
      "6 36.78756 [7.889529] [2.6944556]\n",
      "7 22.135632 [8.192165] [2.7671947]\n",
      "8 13.592511 [8.423858] [2.8203208]\n",
      "9 8.60932 [8.60139] [2.858483]\n",
      "10 5.7007194 [8.737576] [2.88523]\n",
      "11 4.001111 [8.8421955] [2.903271]\n",
      "12 3.0060875 [8.922716] [2.9146738]\n",
      "13 2.4216857 [8.9848385] [2.9210174]\n",
      "14 2.0765972 [9.032913] [2.9235067]\n",
      "15 1.8710079 [9.070262] [2.9230618]\n",
      "16 1.7467407 [9.099421] [2.920385]\n",
      "17 1.6698964 [9.122325] [2.916012]\n",
      "18 1.6207078 [9.140452] [2.9103522]\n",
      "19 1.5876757 [9.154932] [2.903718]\n",
      "20 1.5640838 [9.166624] [2.8963478]\n",
      "21 1.5460203 [9.176186] [2.8884234]\n",
      "22 1.5312132 [9.184119] [2.8800838]\n",
      "23 1.5183269 [9.190808] [2.871435]\n",
      "24 1.5065958 [9.196545] [2.8625576]\n",
      "25 1.4955591 [9.201551] [2.8535137]\n",
      "26 1.4849561 [9.205999] [2.8443503]\n",
      "27 1.4746408 [9.210018] [2.8351033]\n",
      "28 1.4645154 [9.213708] [2.8258002]\n",
      "29 1.4545276 [9.217144] [2.8164618]\n",
      "30 1.4446504 [9.220385] [2.8071039]\n",
      "31 1.4348677 [9.223474] [2.7977388]\n",
      "32 1.4251618 [9.226445] [2.7883756]\n",
      "33 1.4155287 [9.229324] [2.7790215]\n",
      "34 1.4059657 [9.232132] [2.7696817]\n",
      "35 1.3964722 [9.234882] [2.7603602]\n",
      "36 1.3870423 [9.237587] [2.75106]\n",
      "37 1.3776777 [9.240254] [2.7417836]\n",
      "38 1.3683772 [9.242891] [2.7325327]\n",
      "39 1.3591393 [9.245503] [2.7233086]\n",
      "40 1.349964 [9.248095] [2.7141123]\n",
      "41 1.3408515 [9.250667] [2.7049444]\n",
      "42 1.3317988 [9.253223] [2.6958055]\n",
      "43 1.3228086 [9.255766] [2.686696]\n",
      "44 1.3138785 [9.258296] [2.6776161]\n",
      "45 1.3050091 [9.260814] [2.668566]\n",
      "46 1.2961984 [9.263321] [2.659546]\n",
      "47 1.2874501 [9.265818] [2.6505556]\n",
      "48 1.2787602 [9.268305] [2.6415954]\n",
      "49 1.2701288 [9.270782] [2.6326652]\n",
      "50 1.261554 [9.273251] [2.623765]\n",
      "51 1.2530364 [9.275709] [2.6148946]\n",
      "52 1.2445774 [9.278159] [2.606054]\n",
      "53 1.2361771 [9.280601] [2.5972435]\n",
      "54 1.2278311 [9.283033] [2.5884626]\n",
      "55 1.2195427 [9.285459] [2.5797114]\n",
      "56 1.2113111 [9.287875] [2.5709896]\n",
      "57 1.2031329 [9.290283] [2.5622973]\n",
      "58 1.1950125 [9.292683] [2.5536344]\n",
      "59 1.1869456 [9.295074] [2.5450008]\n",
      "60 1.178932 [9.297458] [2.5363963]\n",
      "61 1.1709738 [9.299833] [2.5278208]\n",
      "62 1.163069 [9.3022] [2.5192745]\n",
      "63 1.1552178 [9.30456] [2.510757]\n",
      "64 1.1474215 [9.306911] [2.5022683]\n",
      "65 1.1396734 [9.309255] [2.4938083]\n",
      "66 1.1319816 [9.31159] [2.4853768]\n",
      "67 1.1243379 [9.313918] [2.4769738]\n",
      "68 1.1167494 [9.316237] [2.468599]\n",
      "69 1.1092118 [9.318549] [2.4602528]\n",
      "70 1.101722 [9.320853] [2.4519348]\n",
      "71 1.0942857 [9.32315] [2.443645]\n",
      "72 1.0868986 [9.325438] [2.435383]\n",
      "73 1.0795615 [9.327719] [2.427149]\n",
      "74 1.0722728 [9.329991] [2.418943]\n",
      "75 1.0650375 [9.332256] [2.4107647]\n",
      "76 1.0578475 [9.334514] [2.402614]\n",
      "77 1.0507053 [9.336763] [2.394491]\n",
      "78 1.0436151 [9.339006] [2.3863955]\n",
      "79 1.0365694 [9.341241] [2.3783271]\n",
      "80 1.0295717 [9.343469] [2.3702862]\n",
      "81 1.0226223 [9.345689] [2.3622725]\n",
      "82 1.0157173 [9.347901] [2.3542857]\n",
      "83 1.0088613 [9.350106] [2.3463259]\n",
      "84 1.0020518 [9.3523035] [2.338393]\n",
      "85 0.9952861 [9.354493] [2.330487]\n",
      "86 0.9885683 [9.356675] [2.3226078]\n",
      "87 0.9818942 [9.3588505] [2.3147552]\n",
      "88 0.97526705 [9.361018] [2.306929]\n",
      "89 0.96868163 [9.363178] [2.2991295]\n",
      "90 0.9621438 [9.365332] [2.291356]\n",
      "91 0.9556481 [9.367477] [2.2836092]\n",
      "92 0.9491986 [9.369616] [2.2758884]\n",
      "93 0.94279176 [9.371747] [2.2681937]\n",
      "94 0.93642694 [9.373871] [2.260525]\n",
      "95 0.93010426 [9.375988] [2.2528822]\n",
      "96 0.9238248 [9.378098] [2.2452652]\n",
      "97 0.91758937 [9.3802] [2.237674]\n",
      "98 0.91139555 [9.382296] [2.2301085]\n",
      "99 0.90524256 [9.384384] [2.2225685]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100):\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X:x_data, Y:y_data})\n",
    "        print(step, cost_val, sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 952.42224 [2.7884653] [0.38886172]\n",
      "10 5.13899 [8.963154] [2.0196865]\n",
      "20 0.8055199 [9.396522] [2.0629044]\n",
      "30 0.7347125 [9.443422] [2.0016346]\n",
      "40 0.6865124 [9.463758] [1.9354796]\n",
      "50 0.6415541 [9.481736] [1.8710622]\n",
      "60 0.59953576 [9.499002] [1.808758]\n",
      "70 0.56027347 [9.515686] [1.7485273]\n",
      "80 0.5235802 [9.531814] [1.6903019]\n",
      "90 0.48929128 [9.547404] [1.634015]\n",
      "100 0.45724684 [9.562475] [1.5796025]\n",
      "110 0.42730156 [9.577045] [1.5270023]\n",
      "120 0.39931673 [9.591128] [1.4761535]\n",
      "130 0.37316513 [9.604745] [1.4269979]\n",
      "140 0.34872594 [9.617907] [1.3794788]\n",
      "150 0.3258883 [9.63063] [1.3335426]\n",
      "160 0.30454478 [9.64293] [1.2891359]\n",
      "170 0.28460088 [9.65482] [1.246208]\n",
      "180 0.26596156 [9.666314] [1.2047096]\n",
      "190 0.24854429 [9.677426] [1.1645931]\n",
      "200 0.23226634 [9.688169] [1.1258122]\n",
      "210 0.21705551 [9.698552] [1.0883228]\n",
      "220 0.2028393 [9.7085905] [1.0520818]\n",
      "230 0.18955615 [9.718294] [1.0170474]\n",
      "240 0.17714128 [9.727675] [0.98317975]\n",
      "250 0.16554078 [9.736743] [0.95044005]\n",
      "260 0.15469906 [9.745509] [0.91879076]\n",
      "270 0.14456822 [9.753983] [0.8881958]\n",
      "280 0.13510081 [9.7621765] [0.8586192]\n",
      "290 0.12625208 [9.770096] [0.83002734]\n",
      "300 0.11798372 [9.777752] [0.8023874]\n",
      "310 0.11025735 [9.785152] [0.7756677]\n",
      "320 0.103036426 [9.792307] [0.7498381]\n",
      "330 0.09628811 [9.799223] [0.7248688]\n",
      "340 0.08998183 [9.805908] [0.70073074]\n",
      "350 0.084089056 [9.812372] [0.67739654]\n",
      "360 0.07858193 [9.81862] [0.6548393]\n",
      "370 0.07343562 [9.82466] [0.6330333]\n",
      "380 0.0686267 [9.830498] [0.6119536]\n",
      "390 0.06413227 [9.8361435] [0.5915758]\n",
      "400 0.05993229 [9.841599] [0.5718763]\n",
      "410 0.056007005 [9.846874] [0.5528326]\n",
      "420 0.05233894 [9.851974] [0.53442323]\n",
      "430 0.048911378 [9.856902] [0.5166271]\n",
      "440 0.045708045 [9.861668] [0.49942362]\n",
      "450 0.042714246 [9.866275] [0.48279276]\n",
      "460 0.03991716 [9.870728] [0.46671563]\n",
      "470 0.037303023 [9.875032] [0.4511739]\n",
      "480 0.034859926 [9.879194] [0.4361497]\n",
      "490 0.032576747 [9.883216] [0.4216259]\n",
      "500 0.030443206 [9.887105] [0.40758613]\n",
      "510 0.028449442 [9.890864] [0.39401358]\n",
      "520 0.026586216 [9.894499] [0.38089302]\n",
      "530 0.02484535 [9.898012] [0.36820936]\n",
      "540 0.023218187 [9.901408] [0.35594797]\n",
      "550 0.02169786 [9.904691] [0.3440952]\n",
      "560 0.020276641 [9.907865] [0.33263707]\n",
      "570 0.018948765 [9.910933] [0.32156047]\n",
      "580 0.01770771 [9.913898] [0.31085262]\n",
      "590 0.016548242 [9.916764] [0.30050194]\n",
      "600 0.015464525 [9.919537] [0.29049596]\n",
      "610 0.01445167 [9.922217] [0.28082266]\n",
      "620 0.013505113 [9.924807] [0.27147081]\n",
      "630 0.012620777 [9.927311] [0.26243073]\n",
      "640 0.011794271 [9.929732] [0.25369167]\n",
      "650 0.011021808 [9.932072] [0.24524352]\n",
      "660 0.0102998 [9.934334] [0.23707683]\n",
      "670 0.009625196 [9.936521] [0.22918214]\n",
      "680 0.008994885 [9.938634] [0.22155024]\n",
      "690 0.008405825 [9.940678] [0.21417254]\n",
      "700 0.00785522 [9.942653] [0.20704074]\n",
      "710 0.007340963 [9.944563] [0.20014639]\n",
      "720 0.0068600876 [9.946409] [0.19348149]\n",
      "730 0.0064109527 [9.948194] [0.18703839]\n",
      "740 0.0059909862 [9.949919] [0.18080994]\n",
      "750 0.005598654 [9.951587] [0.17478871]\n",
      "760 0.0052319905 [9.953198] [0.16896819]\n",
      "770 0.0048893383 [9.954757] [0.1633417]\n",
      "780 0.0045690546 [9.956264] [0.1579027]\n",
      "790 0.0042698155 [9.95772] [0.15264438]\n",
      "800 0.0039902166 [9.959127] [0.14756134]\n",
      "810 0.003728944 [9.960489] [0.14264779]\n",
      "820 0.003484713 [9.961804] [0.13789767]\n",
      "830 0.0032564937 [9.963077] [0.13330562]\n",
      "840 0.0030432655 [9.964306] [0.12886655]\n",
      "850 0.0028439804 [9.965495] [0.12457522]\n",
      "860 0.0026577276 [9.966643] [0.12042699]\n",
      "870 0.0024836105 [9.967754] [0.11641688]\n",
      "880 0.002320945 [9.968828] [0.11254025]\n",
      "890 0.002168951 [9.969867] [0.10879246]\n",
      "900 0.0020268771 [9.97087] [0.10516955]\n",
      "910 0.0018941754 [9.97184] [0.10166731]\n",
      "920 0.0017701384 [9.972777] [0.09828185]\n",
      "930 0.0016541468 [9.973684] [0.0950091]\n",
      "940 0.0015459066 [9.974561] [0.09184527]\n",
      "950 0.001444571 [9.975408] [0.08878653]\n",
      "960 0.0013499635 [9.976227] [0.08582991]\n",
      "970 0.0012616079 [9.977018] [0.0829718]\n",
      "980 0.001178961 [9.977783] [0.08020899]\n",
      "990 0.0011017417 [9.978523] [0.07753795]\n",
      "X:5, Y: [49.97105]\n",
      "X:2.5, Y: [25.02313]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(1000):\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X:x_data, Y:y_data})\n",
    "        if step%10==0:\n",
    "            print(step, cost_val, sess.run(W), sess.run(b))\n",
    "            \n",
    "    print('X:5, Y:', sess.run(hypothesis, feed_dict={X:5}))\n",
    "    print('X:2.5, Y:', sess.run(hypothesis, feed_dict={X:2.5}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
